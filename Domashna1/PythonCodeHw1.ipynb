{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52633321-208c-437f-a3d8-1ec38c272098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time  # Import the time module to measure elapsed time\n",
    "\n",
    "# Define the list of crypto symbols\n",
    "symbols = [\n",
    "    'ADIN', 'ALK', 'ALKB', 'AMEH', 'APTK', 'ATPP', 'AUMK', 'BANA', 'BGOR', 'BIKF', 'BIM', 'BLTU',\n",
    "    'CBNG', 'CDHV', 'CEVI', 'CKB', 'CKBKO', 'DEBA', 'DIMI', 'EDST', 'ELMA', 'ELNC', 'ENER', 'ENSA', \n",
    "    'EUHA', 'EUMK', 'EVRO', 'FAKM', 'FERS', 'FKTL', 'FROT', 'FUBT', 'GALE', 'GDKM', 'GECK', 'GECT', \n",
    "    'GIMS', 'GRDN', 'GRNT', 'GRSN', 'GRZD', 'GTC', 'GTRG', 'IJUG', 'INB', 'INHO', 'INOV', 'INPR', \n",
    "    'INTP', 'JAKO', 'JUSK', 'KARO', 'KDFO', 'KJUBI', 'KKST', 'KLST', 'KMB', 'KMPR', 'KOMU', 'KONF', \n",
    "    'KONZ', 'KORZ', 'KPSS', 'KULT', 'KVAS', 'LAJO', 'LHND', 'LOTO', 'LOZP', 'MAGP', 'MAKP', 'MAKS', \n",
    "    'MB', 'MERM', 'MKSD', 'MLKR', 'MODA', 'MPOL', 'MPT', 'MPTE', 'MTUR', 'MZHE', 'MZPU', 'NEME', \n",
    "    'NOSK', 'OBPP', 'OILK', 'OKTA', 'OMOS', 'OPFO', 'OPTK', 'ORAN', 'OSPO', 'OTEK', 'PELK', 'PGGV', \n",
    "    'PKB', 'POPK', 'PPIV', 'PROD', 'PROT', 'PTRS', 'RADE', 'REPL', 'RIMI', 'RINS', 'RZEK', 'RZIT', \n",
    "    'RZIZ', 'RZLE', 'RZLV', 'RZTK', 'RZUG', 'RZUS', 'SBT', 'SDOM', 'SIL', 'SKON', 'SKP', 'SLAV', \n",
    "    'SNBT', 'SNBTO', 'SOLN', 'SPAZ', 'SPAZP', 'SPOL', 'SSPR', 'STB', 'STBP', 'STIL', 'STOK', 'TAJM', \n",
    "    'TBKO', 'TEAL', 'TEHN', 'TEL', 'TETE', 'TIKV', 'TKPR', 'TKVS', 'TNB', 'TRDB', 'TRPS', 'TRUB', \n",
    "    'TSMP', 'TSZS', 'TTK', 'TTKO', 'UNI', 'USJE', 'VARG', 'VFPM', 'VITA', 'VROS', 'VSC', 'VTKS', \n",
    "    'ZAS', 'ZILU', 'ZILUP', 'ZIMS', 'ZKAR', 'ZPKO', 'ZPOG', 'ZUAS'\n",
    "]\n",
    "\n",
    "BASE_URL = \"https://www.mse.mk/mk/stats/symbolhistory/{symbol}\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "}\n",
    "\n",
    "def fetch_data(symbol, start_date, end_date):\n",
    "    # Make a request to fetch data for a given symbol and date range\n",
    "    payload = {\n",
    "        \"FromDate\": start_date,\n",
    "        \"ToDate\": end_date,\n",
    "        \"Code\": symbol,\n",
    "    }\n",
    "    url = BASE_URL.format(symbol=symbol)\n",
    "    response = requests.post(url, data=payload, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for {symbol}\")\n",
    "        return None\n",
    "    return response.text\n",
    "\n",
    "def parse_table(html_content):\n",
    "    # Parse the HTML content and extract table data into a DataFrame\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    table = soup.find(\"table\", {\"id\": \"resultsTable\"})\n",
    "    \n",
    "    if not table:\n",
    "        print(\"No data table found.\")\n",
    "        return None\n",
    "\n",
    "    # Extract headers\n",
    "    headers = [header.text.strip() for header in table.find_all(\"th\")]\n",
    "\n",
    "    # Extract rows\n",
    "    rows = []\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "        columns = row.find_all(\"td\")\n",
    "        row_data = [col.text.strip() for col in columns]\n",
    "        rows.append(row_data)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    return df\n",
    "\n",
    "def save_to_csv(df, symbol, year):\n",
    "    # Save data to a CSV file named by symbol and year\n",
    "    filename = f\"{symbol}_{year}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "def scrape_data_for_all_symbols():\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Loop through each symbol and year range\n",
    "    start_year = 2014\n",
    "    end_year = datetime.now().year\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            print(f\"Fetching data for {symbol} for the year {year}...\")\n",
    "            start_date = f\"01/01/{year}\"\n",
    "            end_date = f\"31/12/{year}\"\n",
    "            html_content = fetch_data(symbol, start_date, end_date)\n",
    "            \n",
    "            if html_content:\n",
    "                df = parse_table(html_content)\n",
    "                \n",
    "                if df is not None:\n",
    "                    save_to_csv(df, symbol, year)\n",
    "\n",
    "    # End the timer and calculate elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Scraping completed in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_data_for_all_symbols()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
